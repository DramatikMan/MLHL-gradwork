{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import multiprocessing as mp\nfrom pathlib import Path\n\nimport pandas as pd\nimport torch\nimport torchvision\nfrom IPython import display\nfrom torch.utils.data import DataLoader\nfrom tqdm.notebook import tqdm_notebook\n\nif torch.cuda.is_available():\n    DEVICE = torch.device(\"cuda:0\")\n    print(\"Using GPU\")\nelse:\n    DEVICE = torch.device(\"cpu\")\n    print(\"Using CPU\")","metadata":{"execution":{"iopub.status.busy":"2023-02-24T16:55:38.574925Z","iopub.execute_input":"2023-02-24T16:55:38.576047Z","iopub.status.idle":"2023-02-24T16:55:39.356157Z","shell.execute_reply.started":"2023-02-24T16:55:38.575962Z","shell.execute_reply":"2023-02-24T16:55:39.355038Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Using GPU\n","output_type":"stream"}]},{"cell_type":"code","source":"root_path = Path(\"/kaggle/input/vegetable-image-dataset/Vegetable Images/\")\n\ndata_train = root_path / \"train\"\ndata_test = root_path / \"test\"\ndata_val = root_path / \"validation\"\n\ntransform = torchvision.transforms.Compose(\n    [\n        torchvision.transforms.Resize((299, 299)),\n        torchvision.transforms.ToTensor(),\n    ]\n)\n\nds_train = torchvision.datasets.ImageFolder(root=data_train, transform=transform)\nds_test = torchvision.datasets.ImageFolder(root=data_test, transform=transform)\nds_val = torchvision.datasets.ImageFolder(root=data_val, transform=transform)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-24T16:55:39.363001Z","iopub.execute_input":"2023-02-24T16:55:39.363731Z","iopub.status.idle":"2023-02-24T16:55:39.509159Z","shell.execute_reply.started":"2023-02-24T16:55:39.363691Z","shell.execute_reply":"2023-02-24T16:55:39.508001Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"model = torch.hub.load(\"pytorch/vision:v0.10.0\", \"inception_v3\", weights=\"DEFAULT\")\n\nfor param in model.parameters():\n    param.requires_grad = False\n    \nclassifier = torch.nn.Linear(model.fc.in_features, len(ds_train.classes))\nmodel.fc = classifier","metadata":{"execution":{"iopub.status.busy":"2023-02-24T16:55:39.512461Z","iopub.execute_input":"2023-02-24T16:55:39.513511Z","iopub.status.idle":"2023-02-24T16:55:39.974102Z","shell.execute_reply.started":"2023-02-24T16:55:39.513464Z","shell.execute_reply":"2023-02-24T16:55:39.973052Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters())\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\nNUM_EPOCHS, BATCH_SIZE, NUM_WORKERS = 5, 64, mp.cpu_count()\n\ndl_train = DataLoader(ds_train, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\ndl_val = DataLoader(ds_val, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\ndl_test = DataLoader(ds_test, BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)","metadata":{"execution":{"iopub.status.busy":"2023-02-24T16:55:39.976969Z","iopub.execute_input":"2023-02-24T16:55:39.977341Z","iopub.status.idle":"2023-02-24T16:55:39.986662Z","shell.execute_reply.started":"2023-02-24T16:55:39.977305Z","shell.execute_reply":"2023-02-24T16:55:39.985558Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Solver:\n    def __init__(self, model, criterion, optimizer, scheduler):\n        self.model = model\n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.stats = pd.DataFrame(columns=[\"accuracy_train\", \"accuracy_validation\"])\n\n    def _display(self):\n        display.clear_output()\n\n        display.display(\n            display.HTML(\n                self.stats.to_html(\n                    formatters={\n                        \"accuracy_train\": lambda x: f\"{x*100:.2f}%\",\n                        \"accuracy_validation\": lambda x: f\"{x*100:.2f}%\",\n                    }\n                )\n            )\n        )\n\n    def _append_stats(self, epoch, acc_train, acc_val):\n        self.stats = pd.concat(\n            (\n                self.stats,\n                pd.DataFrame.from_dict(\n                    {f\"epoch_{epoch}\": [acc_train, acc_val]},\n                    orient=\"index\",\n                    columns=self.stats.columns,\n                ),\n            )\n        )\n\n    def train(\n        self,\n        dl_train,\n        dl_val,\n        usage_percentage=1,\n        num_epochs=NUM_EPOCHS,\n        device=DEVICE,\n    ):\n        batches_to_train = int(round(len(dl_train) * usage_percentage))\n        self.model.to(device)\n\n        for epoch in range(num_epochs):\n            self.model.train()\n            batch_count, acc_train, acc_val = 0, 0, 0\n            self._display()\n\n            for x_batch, y_batch in tqdm_notebook(dl_train, desc=\"Train batches done\"):\n                if usage_percentage != 1 and batch_count > batches_to_train:\n                    break\n\n                batch_count += 1\n\n                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n                pred, _ = self.model(x_batch)\n                loss = self.criterion(pred, y_batch)\n                loss.backward()\n                self.optimizer.step()\n                self.optimizer.zero_grad()\n\n                is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n                acc_train += is_correct.sum().cpu().numpy()\n\n            self.model.eval()\n\n            with torch.no_grad():\n                for x_batch, y_batch in tqdm_notebook(dl_val, desc=\"Validation batches done\"):\n                    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n                    pred = self.model(x_batch)\n                    loss = self.criterion(pred, y_batch)\n\n                    is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n                    acc_val += is_correct.sum().cpu().numpy()\n\n            self.scheduler.step()\n\n            self._append_stats(\n                epoch + 1,\n                acc_train / len(dl_train.dataset),\n                acc_val / len(dl_val.dataset),\n            )\n\n        self._display()","metadata":{"execution":{"iopub.status.busy":"2023-02-24T16:55:39.988424Z","iopub.execute_input":"2023-02-24T16:55:39.988934Z","iopub.status.idle":"2023-02-24T16:55:40.011027Z","shell.execute_reply.started":"2023-02-24T16:55:39.988892Z","shell.execute_reply":"2023-02-24T16:55:40.009654Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"solver = Solver(model, criterion, optimizer, scheduler)\nsolver.train(dl_train, dl_val)","metadata":{"execution":{"iopub.status.busy":"2023-02-24T16:55:40.012961Z","iopub.execute_input":"2023-02-24T16:55:40.013572Z","iopub.status.idle":"2023-02-24T17:04:27.339394Z","shell.execute_reply.started":"2023-02-24T16:55:40.013531Z","shell.execute_reply":"2023-02-24T17:04:27.338136Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy_train</th>\n      <th>accuracy_validation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>epoch_0</th>\n      <td>89.13%</td>\n      <td>98.60%</td>\n    </tr>\n    <tr>\n      <th>epoch_1</th>\n      <td>97.38%</td>\n      <td>99.07%</td>\n    </tr>\n    <tr>\n      <th>epoch_2</th>\n      <td>98.29%</td>\n      <td>99.30%</td>\n    </tr>\n    <tr>\n      <th>epoch_3</th>\n      <td>98.61%</td>\n      <td>99.50%</td>\n    </tr>\n    <tr>\n      <th>epoch_4</th>\n      <td>98.94%</td>\n      <td>99.60%</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"torch.onnx.export(\n    model=solver.model,\n    args=torch.randn(64, 3, 299, 299).to(DEVICE),\n    f=\"/kaggle/working/model.onnx\",\n    input_names=[\"input\"],\n    output_names=[\"output\"],\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-24T17:04:27.341514Z","iopub.execute_input":"2023-02-24T17:04:27.342279Z","iopub.status.idle":"2023-02-24T17:04:37.786960Z","shell.execute_reply.started":"2023-02-24T17:04:27.342230Z","shell.execute_reply":"2023-02-24T17:04:37.785845Z"},"trusted":true},"execution_count":7,"outputs":[]}]}